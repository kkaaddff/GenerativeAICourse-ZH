{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "942335d7",
      "metadata": {},
      "source": [
        "\n",
        "# 使用Gradio构建交互式AI应用\n",
        "\n",
        "本实验将指导你使用 **Gradio** 创建交互式的人工智能应用，重点是构建一个具有流式响应功能的可定制聊天机器人。\n",
        "\n",
        "**Gradio** 是一个Python前端库，它能让你用极少的代码，轻松地为你的AI模型或任意Python函数构建一个美观、易用的Web用户界面。\n",
        "\n",
        "## 准备工作\n",
        "\n",
        "在开始之前，请确保你已经安装了必要的软件包："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a84e9dd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 安装所需软件包\n",
        "%pip install gradio openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "580ae89a",
      "metadata": {},
      "source": [
        "## 1. 配置你的环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aaabe25",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# 从.env文件加载环境变量\n",
        "load_dotenv()\n",
        "\n",
        "# 初始化OpenAI客户端\n",
        "# 注意：为了安全，生产环境中应始终使用环境变量，而不是直接在代码中写入密钥。\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# 验证API密钥是否加载成功\n",
        "if os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    print(\"OpenAI API 密钥已成功加载。\")\n",
        "else:\n",
        "    print(\"错误：未找到OpenAI API密钥！请在.env文件中配置。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d63286",
      "metadata": {},
      "source": [
        "## 2. 你的第一个Gradio界面\n",
        "\n",
        "让我们从创建一个最简单的Gradio界面开始。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cb51446",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 我们定义一个名为 echo 的简单函数，它接收一个消息并原样返回。\n",
        "def echo(message):\n",
        "    return f\"你输入了: {message}\"\n",
        "\n",
        "# 创建一个基础的Gradio界面。gr.Interface() 会为你的函数生成一个Web UI。\n",
        "# 它会自动创建一个网页，包含输入框、输出框和提交按钮。\n",
        "# - fn: 指定要绑定的函数 (这里是 echo)。\n",
        "# - inputs: 定义输入组件的类型 (这里是 \"textbox\")。\n",
        "# - outputs: 定义输出组件的类型 (这里也是 \"textbox\")。\n",
        "# - title 和 description: 用于提供界面的标题和描述，增强用户体验。\n",
        "demo = gr.Interface(\n",
        "    fn=echo,\n",
        "    inputs=\"textbox\",\n",
        "    outputs=\"textbox\",\n",
        "    title=\"回声机器人\",\n",
        "    description=\"一个简单地重复你输入内容的机器人\",\n",
        "    allow_flagging=\"never\" # 禁用标记功能，使界面更简洁\n",
        ")\n",
        "\n",
        "# 启动界面。这会在本地启动一个Web服务器，你可以通过浏览器访问。\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a73821d",
      "metadata": {},
      "source": [
        "## 3. 构建一个基础的聊天机器人\n",
        "\n",
        "接下来，让我们利用OpenAI构建一个简单的聊天机器人。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8427d3c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义一个函数，用于从OpenAI获取响应。这个过程我们在之前的实验中已经熟悉了。\n",
        "def get_response(message):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"你是一个乐于助人的助手。\"},\n",
        "            {\"role\": \"user\", \"content\": message}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# 我们创建与之前完全相同的Gradio界面，但这次将 `fn` 参数替换为 `get_response` 函数。\n",
        "# 当用户在输入框中输入消息并点击提交时，Gradio会自动调用 `get_response` 函数，\n",
        "# 并将返回的AI响应显示在输出区域。\n",
        "chatbot = gr.Interface(\n",
        "    fn=get_response,\n",
        "    inputs=gr.Textbox(placeholder=\"问我任何问题...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"简单AI聊天机器人\",\n",
        "    description=\"一个由OpenAI驱动的AI助手\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# 启动聊天机器人界面\n",
        "chatbot.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d68d20ad",
      "metadata": {},
      "source": [
        "## 4. 创建一个流式响应的聊天机器人"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e408435c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义一个函数来从OpenAI流式获取响应\n",
        "def stream_response(message):\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"你是一个乐于助人的助手。\"},\n",
        "            {\"role\": \"user\", \"content\": message}\n",
        "        ],\n",
        "        stream=True\n",
        "    )\n",
        "    \n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            response += chunk.choices[0].delta.content\n",
        "            # `yield` 是一个Python关键字，它允许函数在不终止的情况下返回一个值。\n",
        "            # 这意味着函数可以稍后被再次调用，并从它离开的地方继续执行。\n",
        "            # 这对于流式响应非常有用，因为它允许我们在生成部分结果时就将其返回。\n",
        "            yield response\n",
        "\n",
        "# 创建一个流式聊天机器人界面\n",
        "streaming_chatbot = gr.Interface(\n",
        "    fn=stream_response,\n",
        "    inputs=\"textbox\",\n",
        "    outputs=\"text\",\n",
        "    title=\"流式AI聊天机器人\",\n",
        "    description=\"一个能够实时流式输出响应的AI助手\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# 启动流式聊天机器人\n",
        "streaming_chatbot.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e61e1d00",
      "metadata": {},
      "source": [
        "## 5. 构建一个有记忆的聊天机器人\n",
        "\n",
        "现在，让我们创建一个更高级的、能够记住对话历史的聊天机器人。同样，我们已经在之前的实验中探讨过其实现原理，现在我们只是将其集成到Gradio界面中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9ae82a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义一个名为 chat 的函数，它接收用户消息和由Gradio管理的对话历史\n",
        "def chat(message, history):\n",
        "    # 用系统提示初始化消息列表\n",
        "    messages = [{\"role\": \"system\", \"content\": \"你是一个乐于助人的助手。\"}]\n",
        "    \n",
        "    # 遍历Gradio传入的对话历史（`history`），它是一个由 [用户消息, 助手消息] 组成的列表\n",
        "    for user_msg, assistant_msg in history:\n",
        "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "        if assistant_msg:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
        "    \n",
        "    # 将当前的用户消息添加到对话中\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "    \n",
        "    # 从OpenAI获取流式响应\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        stream=True\n",
        "    )\n",
        "    \n",
        "    # 逐块返回响应\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            response += chunk.choices[0].delta.content\n",
        "            yield response\n",
        "\n",
        "# 使用 `gr.ChatInterface`，这是一个为聊天机器人量身定制的高级组件，它会自动处理对话历史的格式。\n",
        "memory_chatbot = gr.ChatInterface(\n",
        "    fn=chat,\n",
        "    title=\"有记忆的AI聊天机器人\",\n",
        "    description=\"一个能记住你对话历史的AI助手。\",\n",
        "    examples=[\"给我讲讲机器学习\", \"神经网络是如何工作的？\"],\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "memory_chatbot.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3a8177",
      "metadata": {},
      "source": [
        "## 6. 应用示例：餐厅菜单生成器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4b457d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义一个生成餐厅菜单的函数\n",
        "def generate_menu(restaurant_name, cuisine_type, special_requirements=\"无\"):\n",
        "    prompt = f\"\"\"\n",
        "请为名为“{restaurant_name}”的餐厅创建一个菜单，该餐厅主打“{cuisine_type}”菜系。\n",
        "特殊要求: {special_requirements}\n",
        "\n",
        "菜单应包含:\n",
        "- 3道开胃菜\n",
        "- 4道主菜\n",
        "- 2道甜点\n",
        "\n",
        "对于每道菜，请提供菜名、简短描述和价格。\n",
        "\n",
        "请使用Markdown格式化你的响应，包含合适的标题、样式和章节。\n",
        "在菜单顶部添加一段关于餐厅的简短介绍。\n",
        "\"\"\"\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\", # 使用更强大的模型以获得更好的格式化和创意\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"你是一位专业的餐厅顾问，擅长创作精美且格式规范的菜单。\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# 创建一个菜单生成器界面\n",
        "menu_generator = gr.Interface(\n",
        "    fn=generate_menu,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"餐厅名称\"),\n",
        "        gr.Textbox(label=\"菜系类型 (例如, 意大利菜, 日本料理)\"),\n",
        "        gr.Textbox(label=\"特殊要求 (可选)\", placeholder=\"例如, 提供素食选项\")\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"生成的菜单\"), # 使用Markdown组件以正确显示格式\n",
        "    title=\"餐厅菜单生成器\",\n",
        "    description=\"用AI创建一个专业的餐厅菜单\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# 启动菜单生成器\n",
        "menu_generator.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7036418f",
      "metadata": {},
      "source": [
        "## 7. 进一步学习的资源\n",
        "\n",
        "- [Gradio 官方文档](https://www.gradio.app/docs/)\n",
        "- [OpenAI API 官方文档](https://platform.openai.com/docs/api-reference)"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
